ZTF-8 Notes

Compression format for Unicode texts.

- Valid UTF-8 sequences stand for themselves
- a sequence of (L, M, N) items is only replaced by a codeword as a whole
     - supports string search
- line feeds are identifiable from codes

Compressed items:
 - Prefix/nonsuffix pairs 64 x 196  about 12,000 
 - Invalid-prefix suffix pairs 13 x 64


- take the entire space, multiply it out, then partition by a 
   distribution on lengths???


- easy decoding of length of total length of token referent
- token referent has word length + separator length
- lengths are lengths in codepoints...



ztf-8 encoder

- use an RE_compiler instance on "\b\w{8}\b" without keyesToEOL



places to insert - mark with zeroes
extend stream with 1s equal to popcount



-----------------

dictionaries continually wrap around ....?
Ex.  dictionary for 57 length 3 items, total length 171, keep writing to the
   dictionary entry # mod 57







--------

Scanning requirements for compression:

- we separate characters into two different groups: word chars and not.
- we have word starts, word ends


- word-end marks are on the last byte of the following word-end character
- word-starts: marks are on the last byte of the word-start character



encoding - approx 13.5 bits of info

encode the word, plus the separator

Ensuring that line hashs are recognizable:
  - LFs as possible extension of a word + sep 
  - Other legal line hashs encoded as themselves??

Word suffix - if LF, encode a small number of suffixes,
              if not, encode a larger number

32 lengths - 64 words per length  5 + 6 
- leaves 2.5 bits per suffix
- use the 0.5 for line feeds, ex: when a sequence is illegal + legal suffix, this could indicate
   append a LF,
   otherwise the interpretation is based on the 64 prefix codes * 192 nonsuffix codes

32 lengths, 32 words per length, 8 suffix codes
  prefix-ASCII scheme can do
  prefix-prefix gives 4 more suffix codes 



4 length groups 2-bit encoding,
2-3, 4-8, 9-16, 17-32
length groups have variable number of length bits
2-3:1, 4-8:2, 9-16:3, 17-32:4


length group 2-3 thus has 10 bits remaining = 128 entries per length + 3bit suffix code











-----------
UCD library separation (assume regexp keying can be pulled out...)
  - own CMake file???
  - separately compile, never





--------------------------------

sparse stream processing....
   pext/pdep internal

given an extract stream and a deposit stream...
  - extract n source bits deposit m computed bits
    - pextract stream::  gb range stream in gb space  -  gb deposit stream in unicode space

given a 1:1 extract-deposit,   when is it worthwhile
    - we need sufficient computational work to justify (m+n) * (blocksize/scansize) extract/deposit operations per block
    - 8 codepoint table n ternary operations
    - 64 codepoint table 8n ternary operations per block + combining say 12n
    - 256 codepoint table 32n ternary ops


--------------

optimization with a strictly increasing table ....
   -  parallel logic to determine the amount to add ....
   -  for a given block the amount to add will be within a fixed small range...


---------------------


_mm512_test_epi64_mask(a, a) 
   -  performs ICmpNE(a, zeroinitializer) in a single operation - setting 1 bits in mask if any one bit in field are set.




---------------

ZTF-8 encoding

Use two-byte codes for short words
Use three-byte codes for longer words

? use bare suffix for 2-byte combinations?

2-byte code words:
  - illegal prefix, followed by any  13 * 256
  - legal prefix, followed by non-prefix  51 * 192
  ?? bare suffix (64)

3rd byte:  
  - bits identify exact length within group
  - eg. length group 5-8, use 2 bits to refine - 64 codes
                     9-16 use 3 bits to refine - 32 codes
                     17-32 use 4 bits to refine - 16 codes



Let N_i be the number of codewords allocated for coded strings of length i

Divide up prefixes as follows
  - C0-EF  prefixes of 2-byte codewords
    F0-FF  prefixes of 3-byte+ codewords

    for 2-byte codewords - allocate by
       number of length
       196 nonsuffix bytes * 48 prefixes


Encoding at word char start
   - scan for word char end, then next word char
   - length is from word char start to next word char start
   - word_to_encode = word_from(current to next word char start)
   - if word_to_encode in dict[length]:
        codeword = dict[word_to_encode]
     else 
        codeword = (current_codeword[length] + 1) mod codeword_count(length)

Implementing LRU strategy
   - kick out words only when we have a distinct number of words
   - circular buffer has 
          next_word, oldest_word
   - when we find a word, it is in buffer at position found_word
          buffer[next_word] = buffer[found_word]
          buffer[found_word] = buffer[oldest_word]
          nextword = (nextword + 1) mod buffer_size(length)
          oldest_word = (oldest_word + 1) mod buffer_size(length)

       - not quite an LRU strategy, but workable
       - actual LRU
          for w = found_word downto oldest_word
            buffer_word[w mod buffer_size(length)] = buffer_word[w-1 mod buffer_size(length)]
            - implement using wide SIMD registers and shifts
              256 entries per length max - can process 64 at a time using single byte codes 

- alternative:  use hashing, words are stored with hash key
       - eject words on collision....
       - or use cuckoo hashing ....



----
decoding - parallel identification of codewords

have prefix, suffix, illegal prefix, ASCII byte classes

use C2-DF as prefixes of 2-byte UTF-8 (128), or 2-byte ZTF-8 codewords

--
in a run of C2-DF codes, every 2nd one is a data suffix  
   - 

E0-EF codes for 3-byte sequences/codewords
  - allow only ASCII for 2nd, 3rd byte?

F0-F4 codes
  - can only appear as 1st of a 4-byte sequence?
  -   (or immediately after 2-byte code)

Suppose C2-DF can only occur in two-byte sequences (30 bytes).

Suppose:
  in a run of C2-F4 codes, every 2nd one must be a data suffix
  disallow these values as 3rd byte of 3-byte sequence, or 4th byte of 4-byte sequence

- Using the run technique, we can identify all prefixes.

3-byte codewords E0-EF prefix, 196 nonsuffix, 209 non-prefix
   16 x 196 x 209 = 640K codes 




Algorithm to find codeable character sequences
  - find an initial symbol in \p{word} at position i
  - find the first following symbol in \P{word} at position j
  - find the first following symbol in [\p{word}\p{LB}] at position k

Determining the codeword sequence for a codeable character sequence
  - let L = k - i + 1
  - if L > max_codeable_sequence_limit emit without encoding and continue
  - if length == 2 {
        lookup in length_2 table
           if codebyte found, emit codebyte and continue (C0, C1, F5-FF)
           else 
              emit coded sequence
              if last != LB:  // no length codewords reserved for this case 
                codebyte=allocate_codebyte(coded sequence)
    }
  - if length == 3 {
        lookup in length_3 table
           if codebyte found, emit codebyte and continue (0x80-0xFF)
           else 
              emit coded sequence
              if last = LB, allocation_range = {0xFB, 0xFF}
              else allocation range = {0x80, 0xFA}
                allocate_codebyte_from allocation_range
    }


codeword_index   count encoded_sequence_length  is_LB_terminated  codes
0..12              13          2                      no              (C0, C1, F5-FF)
13-72              60          3                      no              80-FA
73-76               4          3                      yes             FB-FF
77-252            176          4                      no              (C2),(0x0-0x7F, 0xC0-0xEF)
253-268            16          4                      yes             (C2),(0xF0-0xFF)
269-444           176          5                      no              (C3),(0x0-0x7F, 0xC0-0xEF)
445-460            16          5                      yes             (C3),(0xF0-0xFF)






parallel encoding??
 - length sorting of symbols

parallel decoding??


------
Initial system: do not worry about using shorter versions of words...





-------
Length of non-word extensions

expect very many " "
       many      ", "
       many      ". "
       many      "\n"
       many      "\" "
       many      " \""


4-byte space?
F0-F4 00-7F, 00-7F, 00-7F
23 bits
8,000,000,000
   combinations
   could certainly include 8 common extensions

only want to use 4-byte encodings for 10-byte strings +   

Codeable substring...




We separate streams into three subsets
  - line hashs, word hashs, others


Encodeable Substrings

Given a text, partition it into encodeable substrings defined as follows.

An encodable substring of T is a maximum length substring T_m..T_n such that
        for all i >=m, i < n, isNonLineHash(T_i) 
   - there exists k such that:
        for all i: i >= m, i < k: isWordChar(T_i)
        for all i: i >=k, i <= n: isNonWordChar(T_i)
   
The maximum length criteria means that:
    m = 0 or isNonWordChar(T_{m-1})
    n = L-1 or isLineHash(T_n) or is WordChar(T_{n+1})


Bit streams for identifying encodeable substrings
   - wordchar stream, line hash stream

First positions of encodeable substrings:
   - i such that i = 0, or isLineHash T_{i-1} or isNonWordChar(T{i-1}) and isWordChar(T{i})

END-OF-FILE:
   encodeable strings always have a nonWordChar, except possibly at EOF


ZTF-8_PlainText_Parser produces 
  - the bit stream marking wordChar end positions of encodeable substrings (first nonWordChar or EOF)
  - the bit stream marking end positions of encodeable substrings 








  
start is (a) every wordChar after a nonWordChar and every char after a LB, and position 0

Hashs: mark the end of an encodeable substring : implicit at start/end of file
    
Switches: nonWordChar after SOF or Char, or EOF after Char










ZTF-8_CipherText_Parser 
   - must mark codewords and encodeable substrings


ZTF-8 Reporter
   - ideally call at end of each encodeable substring, with
       nonWordChar position
   - each call gives a word, based on pending start position (initially 0)

scan to first nonWordChar position.
   - pending nonWordChar pos
   - scan to following first position
   - report 




Start/End scanner
  - scan to start, scan to end (which may be same as start)




-------

Length-sorted scanning
   - when we are length sorted, the density will be lower, so the two-level
       scanning strategy may be better



----

- kernel 1 - word chars
- kernel 2 - marks - place at the end byte rather than one past?
       but root mark could be at position 0....





---------
ZTF-8 property
   for any given string of word characters
      - the word may only occur on lines which have
         one of the following
             - the full string in plain text
             - one of the two hash values for the string (two hash functions used for each string length)
             - one of the hash values of longer words previously encountered for it....


Revise:
  - only use positions within file.
  - first byte of first character of word/symbol
  - last byte of word_root
  - last byte of extension


ZTF-8 Run Encoding


Look for runs of
  - single bytes  - (or leave to byte pair detection?)
  - byte pairs
  - byte triples


Run Pair Encoding
F5 xx yy for a run of 4 xx yy xx yy
F6 xx yy for a run of 6 




Run encodings
   - ASCII runs  :  Prefix C0 
     - can use high bit of next byte to encoding length say 3/4 
     - or filter out repeatable ASCII characters - exclude 00-1F, 30-39, 41-5A, 61-7A, 7F `
     - leaves 32 characters, encodable in 5 bits
     - 3 bits for length encoding
     000 - 3, 001 - 4, 010 - 5, 011 - 6, ... 111 - next byte has length to 






Run compression
  - 2 byte runs: 
  - prefix code F5: 
    - assumption: first character of run is a length 2 prefix
       - 2-byte codable sequence  110abcde 10fghijk
       - encoded run
           - F5 xyzabcde vwfghijk
           - have 5 bits to express run length
              xyzvw = 00000:  total length 4
              xyzvw = 00001:  total length 6
              xyzvw = 00010:  total length 8
              xyzvw = 00011:  total length 10

    - alternative:  first character is a prefix, (but could be two 3 or 4)
      - 2-byte codable sequence  11abcdef 10ghjkmn
      - encoded run: F5 xyabcdef zwghjkmn
      - have 4 bits to express run length
      - express run length in characters 
          for xyzw = 0000 to 0111  run_length = xyzw + 2  (up to 9)
          for xyzw = 1000 to 1111  run_length = 2^{yzw} + 9  (up to 265)




length sorting ...


----
Next experimental program

- compression for a particular fixed length
Say 8


   - Hashing in byte space or bit space?

   - Lookup in byte space

      - For each length, a contiguous array of values, indexed by hash code for the length


      - Decoding process, 
          - need to extract the hash code, calculate the output position
          - better: first perform expansion according to parallel spread by mask calculation
          - then iterate through expanded positions, replacing values in place...

          - n-byte compressed code (1-4)
              - part is a length code
              - remainder is a hash code (or hash code plus following symbol code)
              - first decode length codes
              - then calculate spread mask and do the expansion
              - finally use length-based iteration to replace hash codes with full strings
                  - convention: insertions before code
                  - therefore hash code decoding based on value at the final positions



HashDecodingKernel(   length_group)


Note: marker bits need to be on last position of the code to
  guarantee that all the positions for the code and the 
  dictionary symbol are available.


/*  UniLengthHashDecoder
    This kernel processes a stream of data including text mixed with hash codes,
    expanding selected hash codes to words of a particular length.   At each
    position marked by the position_marks bit stream, a hash code is extracted
    from the symbol stream and the result is written to the corresponding location
    in the decoded stream.

    Hashing parameters
        - hash_table_size : number of hash entries
        - encoded_hash_length  : number of bytes of the encoded hash symbol
        - encoded_hash_offset  : an offset to subtract from the encoded hash symbol
        - hash multiplier : multiplier to apply to decoded hash offset
        - bit_select:  amount to shift the multiplied hash value by.

*/

UniLengthHashDecoder(unsigned word_length, StreamSet * position_marks, StreamSet * symbol_stream, StreamSet * decoded, Scalar * hash_table)

     base_length = floor_log2(word_length)
     base_type = b->getIntNTy(8 * base_length);
     code_length = (some function that returns the code length)
     code_type = 
     





LengthGroupHashDecoder
  - design for lengths k...2k-1, use two k-byte writes per symbol
  - particular length within a group is a dynamic value to be
    computed per symbol
  - should all lengths be confined to use the same code length
     - two byte codes C2-DF followed by nonsuffix  192 * 30, use for codes 4-7 bytes



Simple Hash Conflict Resolution
   - we have one entry per hash value, always refers to the last string encountered with that value


symbol_stream
   - has codewords mixed with plaintext UTF-8,
         codewords are illegal UTF-8 sequences
   - decoding must parse plaintext items according to ZTF-8 word boundary rules
       - these plaintext items give new hashes
           - we would need to mix decoding of items with calculation of hashes
           - alternative - process in 4K segments, only keep last hash value in case of
               conflicts

encoding -
  we find symbol plus extension
  - hash both the symbol and the symbol plus the extension


USE FNV hash ????   restricted to # of bits  

What about parallel hashing????


First use sequential hashing



---
  Simple binary reduction hash
     - let k = ceil_log2(symbol_length) - 1
           K = 2^K
           if (k == 0) { // two bytes
               hash1 = ord(sym[0])
               hash2 = ord(sym[1])
           }
                hash1 = hash(sym[0..K-1])
                hash2 = hash(sym[-K..-1])
           }
           return (hash1 * 17 + hash2) mod 128

----


Encoding
  - partition according to ZTF-8
  - length group pass --> to codes of some fixed length
      - codes are embedded "in place"
      - construct an extraction mask that extracts only the length required

Extraction mask




Encoding
   - ZTF-8 boundaries
   - length 4 marks
   - scan length 4 items
       - for each item, calculate hash
         - if hash_table[hash] == the current string, 
              mark 2 items for deletion
              mark 2 items for the hash value
           else if hasn_table[hash] empty
              store this string in the hash table
       - apply deletion
           - bytespace deletion ???
    - emit output

Decoding
   - ZTF-8 boundaries
   - ZTF-8 codewords
   - length 4 marks
   - compute expansion mask 2->4
   - expand, inverse transpose


   hash decoding kernel
      need both steps in one kernel, unless we have a shared hash table....
   - scan length 4 items
       - for each item, calculate hash
         - if hash_table[hash] empty 
              store this string in the hash table
   - scan length 4 codewords
       - for each, compute hash
            write hash_table[hash]
            


4 byte codewords
  use 0xC4, 0xC5 followed by 0x00-0x127 as 4-byte codewords: 256 total


ZTF-8 boundaries
  - word marks kernel   + u8 lookahead : rootMarks + wordEnds
  - simplify??  word ends only  on last byte,  word end is any position that 
      the end byte of a nonwordchar followed by either EOF or the first byte of a word char.


Use a bixnum for expansion 
   - this will eventually be required in all cases.


starts = inFile(Advance(not_ends, 1))
len1_ends = starts & ends
gt1_ends = ends ^ len1_ends
gt1_starts = starts &~ len1_ends
len2_ends = advance(gt1_starts, 1) & gt1_ends
gt2_ends = 


What about using runs and run bixnums???
   problem is modulo arithmetic
   but we can compute the >8 or > 16 masks 


- this seems good....




Hash Scan Kernel

   - assume we have the HashMarks on the last byte of each symbol


DecompressionKernel
     

ZTF_InsertionLengthKernel

/* 
    This kernel decodes the insertion length for two-byte ZTF code symbols
    in the range 0xC2-0xDF.   The insertion length is the number of zero
    bytes to insert so that, after insertion the zeroes together with the
    encoded symbol can be replaced by the dictionary symbol of the appropriate
    length.

    The following table shows the pattern of the insertion lengths.
    0xC2, 0xC3   final length 3, insertion length 1
    0xC4, 0xC5   final length 4, insertion length 2
    0xC6, 0xC7   final length 5, insertion length 3
    ...
    0xDE, 0xDF   final length 17, insertion length 15

    As it turns out, the insertion length calculation is very simple for
    the given symbols: simply used bits 1 through 4 of the basis stream.
*/

class ZTF_ExpansionDecoder final: public PabloKernel {
public:
    ZTF_ExpansionDecoder(const std::unique_ptr<kernel::KernelBuilder> & b, StreamSet * const basis, StreamSet * insertBixNum)
    : PabloKernel(b, "byteRun", {Binding{"basis", basis, FixdedRate(), LookAhead(1)}}, {Binding{"insertBixNum", insertBixNum}}) {}
    bool isCachable() const override { return true; }
    bool hasSignature() const override { return false; }
protected:
    void generatePabloMethod() override;
};

void ZTF_ExpansionDecoder::generatePabloMethod() {
    PabloBuilder pb(getEntryScope());
    std::vector<PabloAST *> basis = getInputStreamSet("basis");
    std::unique_ptr<cc::CC_Compiler> ccc;
    ccc = make_unique<cc::Parabix_CC_Compiler_Builder>(getEntryScope(), basis);
    PabloAST * ASCII_lookahead = pb.createNot(pb.createLookAhead(basis[7], 1));
    PabloAST * const ZTF_Sym = pb.createAnd(ccc->compileCC(re::makeByte(0xC2, 0xDF)), ASCII_lookahead);
    Var * lengthVar = getOutputStreamVar("insertBixNum");
    for (unsigned i = 0; i < 4; i++) {
        pb.createAssign(pb.createExtract(lengthVar, pb.getInteger(i)), pb.createAnd(ZTF_sym, basis[i+1]));
    }
}



BoundedRate for Source stream???
   - similar to scan key, we cannot release all of the source stream
        - processed item count will be shorter than input by hash length


Suppose that hash marks are on the first position of the expanded key space
   - if the space goes beyond the stride, we can put the extra data into the
     kernel state...
   - output can be purely FixedRate()



FixedLengthHashDecoder::FixedLengthHashDecoder(const std::unique_ptr<kernel::KernelBuilder> & b, 
                                               unsigned keyLength,
                                               StreamSet * const keyMarks,
                                               StreamSet * const hashMarks, StreamSet * const Source,
                                               StreamSet * const Result) 
    : MultiBlockKernel(b, "length_" + std::to_string(hashLength) + "hash_decoder",
// inputs
{Binding{"keyMarks", keyMarks} ,Binding{"hashMarks", hashMarks} ,Binding{"Source", Source, FixedRate(), { Deferred() }}},
// outputs
{Binding{"Result", Result},
// scalars
{}, {},
// kernel state
{InternalScalar{ArrayType::get(b->getInt8Ty(), keyLength * 256), "hashTable"}}) {
    addAttribute(SideEffecting());
    setStride(std::min(b->getBitBlockWidth() * strideBlocks, SIZE_T_BITS * SIZE_T_BITS));
}

class LengthGroupDecompression : public MultiBlockKernel {
public:
    LengthGroupDecompression(const std::unique_ptr<kernel::KernelBuilder> & b,
                               StreamSet * keyMarks,
                               StreamSet * const hashMarks, StreamSet * const byteData,
                                StreamSet * const result, unsigned strideBlocks = 8)
    : MultiBlockKernel(b, "LengthGroupDecompression",
                              {Binding{"keyMarks", keyMarks},
                                  Binding{"hashMarks", hashMarks},
                                  Binding{"byteData", byteData, FixedRate(), {Deferred()}}},
                              {Binding{"result", result, BoundedRate(0,1)}}, {}, {},
                              // Hash table 8 length-based tables with 256 16-byte entries each.
                              {InternalScalar{b->getBitBlockType(), "pendingMaskInverted"},
                                  InternalScalar{ArrayType::get(b->getInt8Ty(), 8 * 16 * 256), "hashTable"}}) {
                                      setStride(std::min(b->getBitBlockWidth() * strideBlocks, SIZE_T_BITS * SIZE_T_BITS));
                                  }
    bool isCachable() const override { return true; }
    bool hasSignature() const override { return false; }
private:
    void generateMultiBlockLogic(const std::unique_ptr<kernel::KernelBuilder> & iBuilder, llvm::Value * const numOfStrides) override;
};




void LengthGroupDecompression::generateMultiBlockLogic(const std::unique_ptr<KernelBuilder> & b, Value * const numOfStrides) {

    ScanWordParameters sw(b, mStride);

    Module * const m = b->getModule();
    Constant * sz_STRIDE = b->getSize(mStride);
    Constant * sz_BLOCKS_PER_STRIDE = b->getSize(mStride/b->getBitBlockWidth());
    Constant * sz_ZERO = b->getSize(0);
    Constant * sz_ONE = b->getSize(1);
    Constant * sz_BITS = b->getSize(SIZE_T_BITS);
    Constant * sz_MAXBIT = b->getSize(SIZE_T_BITS - 1);
    Type * sizeTy = b->getSizeTy();
    Type * int64PtrTy = b->getInt64Ty()->getPointerTo();

    BasicBlock * const entryBlock = b->GetInsertBlock();
    BasicBlock * const stridePrologue = b->CreateBasicBlock("stridePrologue");
    BasicBlock * const stridePrecomputation = b->CreateBasicBlock("stridePrecomputation");
    BasicBlock * const strideMasksReady = b->CreateBasicBlock("strideMasksReady");
    BasicBlock * const keyProcessingLoop = b->CreateBasicBlock("keyProcessingLoop");
    BasicBlock * const storeKey = b->CreateBasicBlock("storeKey");
    BasicBlock * const nextKey = b->CreateBasicBlock("nextKey");
    BasicBlock * const dispatch = b->CreateBasicBlock("dispatch");
    BasicBlock * const keyesDone = b->CreateBasicBlock("keyesDone");
    BasicBlock * const stridesDone = b->CreateBasicBlock("stridesDone");
    BasicBlock * const callFinalizeScan = b->CreateBasicBlock("callFinalizeScan");
    BasicBlock * const scanReturn = b->CreateBasicBlock("scanReturn");

    Value * const initialPos = b->getProcessedItemCount("keyResult");
    Value * const avail = b->getAvailableItemCount("Source");
    b->CreateBr(stridePrologue);

    b->SetInsertPoint(stridePrologue);
    // Set up the loop variables as PHI nodes at the beginning of each stride.
    PHINode * const strideNo = b->CreatePHI(sizeTy, 2);
    strideNo->addIncoming(sz_ZERO, entryBlock);
    Value * stridePos = b->CreateAdd(initialPos, b->CreateMul(strideNo, sz_STRIDE));
    Value * strideBlockOffset = b->CreateMul(strideNo, sz_BLOCKS_PER_STRIDE);
    Value * nextStrideNo = b->CreateAdd(strideNo, sz_ONE);
    b->CreateBr(stridePrecomputation);
    // Precompute index masks for one stride of the key result and line hash streams,
    // as well as a partial sum popcount of line numbers if line numbering is on.
    b->SetInsertPoint(stridePrecomputation);
    PHINode * const keyMaskAccum = b->CreatePHI(sizeTy, 2);
    keyMaskAccum->addIncoming(sz_ZERO, stridePrologue);
    PHINode * const hashMaskAccum = b->CreatePHI(sizeTy, 2);
    hashMaskAccum->addIncoming(sz_ZERO, stridePrologue);
    PHINode * const blockNo = b->CreatePHI(sizeTy, 2);
    blockNo->addIncoming(sz_ZERO, stridePrologue);
    Value * strideBlockIndex = b->CreateAdd(strideBlockOffset, blockNo);
    Value * keyBitBlock = b->loadInputStreamBlock("keyMarks", sz_ZERO, strideBlockIndex);
    Value * hashBitBlock = b->loadInputStreamBlock("hashMarks", sz_ZERO, strideBlockIndex);
    Value * const anyKey = b->simd_any(sw.width, keyBitBlock);
    Value * const anyHash = b->simd_any(sw.width, hashBitBlock);
    Value * keyWordMask = b->CreateZExtOrTrunc(b->hsimd_signmask(sw.width, anyKey), sizeTy);
    Value * hashWordMask = b->CreateZExtOrTrunc(b->hsimd_signmask(sw.width, anyHash), sizeTy);
    Value * keyMask = b->CreateOr(keyMaskAccum, b->CreateShl(keyWordMask, b->CreateMul(blockNo, sw.WORDS_PER_BLOCK)), "keyMask");
    Value * hashMask = b->CreateOr(hashMaskAccum, b->CreateShl(hashWordMask, b->CreateMul(blockNo, sw.WORDS_PER_BLOCK)), "hashMask");
    Value * const nextBlockNo = b->CreateAdd(blockNo, sz_ONE);
    keyMaskAccum->addIncoming(keyMask, stridePrecomputation);
    hashMaskAccum->addIncoming(hashMask, stridePrecomputation);
    blockNo->addIncoming(nextBlockNo, stridePrecomputation);
    b->CreateCondBr(b->CreateICmpNE(nextBlockNo, sz_BLOCKS_PER_STRIDE), stridePrecomputation, strideMasksReady);

    b->SetInsertPoint(strideMasksReady);
    // First iterate through the new keys and update the hash table as
    // appropriate.   Each key is hashed, and is entered into the hash
    // table if there is not already an entry for that hash code.
    Value * keyWordBasePtr = b->getInputStreamBlockPtr("keyMarks", sz_ZERO, strideBlockOffset);
    keyWordBasePtr = b->CreateBitCast(keyWordBasePtr, sw.pointerTy);
    b->CreateUnlikelyCondBr(b->CreateICmpEQ(keyMask, sz_ZERO), keysDone, keyProcessingLoop);


    b->SetInsertPoint(keyProcessingLoop);
    PHINode * const keyMaskPhi = b->CreatePHI(sizeTy, 2);
    keyMaskPhi->addIncoming(keyMask, strideMasksReady);
    PHINode * const keyWordPhi = b->CreatePHI(sizeTy, 2);
    keyWordPhi->addIncoming(sz_ZERO, strideMasksReady);
    Value * keyWordIdx = b->CreateCountForwardZeroes(keyMaskPhi, "keyWordIdx");
    Value * nextKeyWord = b->CreateZExtOrTrunc(b->CreateLoad(b->CreateGEP(keyWordBasePtr, keyWordIdx)), sizeTy);
    Value * theKeyWord = b->CreateSelect(b->CreateICmpEQ(keyWordPhi, sz_ZERO), nextKeyWord, keyWordPhi);
    Value * keyWordPos = b->CreateAdd(stridePos, b->CreateMul(keyWordIdx, sw.WIDTH));
    Value * keyMarkPosInWord = b->CreateCountForwardZeroes(theKeyWord);
    Value * keyMarkPos = b->CreateAdd(keyWordPos, keyMarkPosInWord, "keyEndPos");
    //b->CallPrintInt("keyMarkPos", keyMarkPos);
    /* Determine the key length. */
    Value * const lgthPtr = b->getRawInputPointer("symbolLengths", keyMarkPos);
    Value * keyLength = b->CreateAdd(b->CreateZExt(b->CreateLoad(lgthPtr), sizeTy), b->getSize(2));
    Value * keyStartPos = b->CreateSub(keyMarkPos, b->CreateSub(keyLength, b->getSize(1)));
    //b->CallPrintInt("keyLength", keyLength);
    // keyOffset for accessing the final 8 bytes of an entry.
    Value * keyOffset = b->CreateSub(keyLength, b->getSize(8));
    //b->CallPrintInt("keyOffset", keyOffset);
    // Get the hash of this key.
    Value * const keyPtr = b->getRawInputPointer("hashValues", keyMarkPos);
    Value * keyHash = b->CreateZExt(b->CreateLoad(keyPtr), sizeTy);
    //b->CallPrintInt("keyHash", keyHash);
    // Starting with length 9, the length-based subtables are 16 * 256 = 4K each.
    Value * hashTableBasePtr = b->CreateBitCast(b->getScalarFieldPtr("hashTable"), b->getInt8PtrTy());
    //b->CallPrintInt("hashTableBasePtr", hashTableBasePtr);
    Value * hashTablePtr = b->CreateGEP(hashTableBasePtr, b->CreateMul(b->CreateSub(keyLength, b->getSize(9)), b->getSize(16 * 256)));
    //b->CallPrintInt("hashTablePtr", hashTablePtr);
    Value * tblEntryPtr = b->CreateGEP(hashTablePtr, b->CreateMul(keyHash, b->getSize(16)));
    // Use two 8-byte loads to get hash and symbol values.
    //b->CallPrintInt("tblEntryPtr", tblEntryPtr);
    Value * tblPtr1 = b->CreateBitCast(tblEntryPtr, int64PtrTy);
    //b->CallPrintInt("tblPtr1", tblPtr1);
    Value * tblPtr2 = b->CreateBitCast(b->CreateGEP(tblEntryPtr, keyOffset), int64PtrTy);
    //b->CallPrintInt("tblPtr2", tblPtr2);
    Value * symPtr1 = b->CreateBitCast(b->getRawInputPointer("byteData", b->getInt32(0), keyStartPos), int64PtrTy);
    //b->CallPrintInt("symPtr1", symPtr1);
    Value * symPtr2 = b->CreateBitCast(b->getRawInputPointer("byteData", b->getInt32(0), b->CreateAdd(keyStartPos, keyOffset)), int64PtrTy);
    //b->CallPrintInt("symPtr2", symPtr2);
    // Check to see if the hash table entry is nonzero (already assigned).
    Value * sym1 = b->CreateLoad(symPtr1);
    //b->CallPrintInt("sym1", sym1);
    Value * sym2 = b->CreateLoad(symPtr2);
    //b->CallPrintInt("sym2", sym2);
    Value * entry1 = b->CreateLoad(tblPtr1);
    //b->CallPrintInt("entry1", entry1);
    Value * entry2 = b->CreateLoad(tblPtr2);
    //b->CallPrintInt("entry2", entry2);
    Value * isEmptyEntry = b->CreateICmpEQ(b->CreateOr(entry1, entry2), b->getInt64(0));
    
    b->CreateCondBr(isEmptyEntry, storeKey, nextKey);
    b->SetInsertPoint(storeKey);
    // We have a new symbols that allows future occurrences of the symbol to
    // be compressed using the hash code.
    b->CreateStore(sym1, tblPtr1);
    b->CreateStore(sym2, tblPtr2);
    b->CreateBr(nextKey);
    
    b->SetInsertPoint(nextKey);
    Value * dropKey = b->CreateResetLowestBit(theKeyWord);
    Value * thisWordDone = b->CreateICmpEQ(dropKey, sz_ZERO);
    // There may be more keys in the key mask.
    Value * nextKeyMask = b->CreateSelect(thisWordDone, b->CreateResetLowestBit(keyMaskPhi), keyMaskPhi);
    BasicBlock * currentBB = b->GetInsertBlock();
    keyMaskPhi->addIncoming(nextKeyMask, currentBB);
    keyWordPhi->addIncoming(dropKey, currentBB);
    b->CreateCondBr(b->CreateICmpNE(nextKeyMask, sz_ZERO), keyProcessingLoop, keysDone);
    
    b->SetInsertPoint(keysDone);
    Value * hashWordBasePtr = b->getInputStreamBlockPtr("hashMarks", sz_ZERO, strideBlockOffset);
    hashWordBasePtr = b->CreateBitCast(hashWordBasePtr, sw.pointerTy);
    b->CreateUnlikelyCondBr(b->CreateICmpEQ(hashMask, sz_ZERO), hashesDone, hashProcessingLoop);


    b->SetInsertPoint(hashProcessingLoop);
    PHINode * const hashMaskPhi = b->CreatePHI(sizeTy, 2);
    hashMaskPhi->addIncoming(hashMask, keysDone);
    PHINode * const hashWordPhi = b->CreatePHI(sizeTy, 2);
    hashWordPhi->addIncoming(sz_ZERO, keysDone);
    Value * hashWordIdx = b->CreateCountForwardZeroes(hashMaskPhi, "hashWordIdx");
    Value * nextHashWord = b->CreateZExtOrTrunc(b->CreateLoad(b->CreateGEP(hashWordBasePtr, hashWordIdx)), sizeTy);
    Value * theHashWord = b->CreateSelect(b->CreateICmpEQ(hashWordPhi, sz_ZERO), nextHashWord, hashWordPhi);
    Value * hashWordPos = b->CreateAdd(stridePos, b->CreateMul(hashWordIdx, sw.WIDTH));
    Value * hashEndPosInWord = b->CreateCountForwardZeroes(theHashWord);
    Value * hashEndPos = b->CreateAdd(hashWordPos, hashEndPosInWord, "hashEndPos");

    Value * theHash = b->CreateZExt(b->CreateLoad(b->CreateGEP(  
    // Determine the position to write the hash table entry.
    Value * keyStartPos = b->CreateSub(hashEndPos, b->getSize(keyLength-1));
    b->CreateMemCpy(keyStartPtr, hashEntryPtr, hashLength);

    b->SetInsertPoint(nextHash);
    Value * dropHash = b->CreateResetLowestBit(theHashWord);
    Value * thisWordDone = b->CreateICmpEQ(dropHash, sz_ZERO);
    // There may be more hashs in the hash mask.
    Value * nextHashMask = b->CreateSelect(thisWordDone, b->CreateResetLowestBit(hashMaskPhi), hashMaskPhi);
    BasicBlock * currentBB = b->GetInsertBlock();
    hashMaskPhi->addIncoming(nextHashMask, currentBB);
    hashWordPhi->addIncoming(dropHash, currentBB);
    b->CreateCondBr(b->CreateICmpNE(nextHashMask, sz_ZERO), hashProcessingLoop, strideDone);


    b->SetInsertPoint(strideDone);
    strideNo->addIncoming(nextStrideNo, strideDone);
    b->CreateCondBr(b->CreateICmpNE(nextStrideNo, numOfStrides), stridePrologue, stridesDone);

    b->SetInsertPoint(stridesDone);
    Value * processed = b->CreateSub(avail, b->getSize(keyLength));
    b->SetProcessedItemCount("Source", processed);
    b->SetProducedItemCount("Result", processed);



-----



class LengthGroupCompressionMask : public MultiBlockKernel {
public:
    LengthGroupCompressionMask(const std::unique_ptr<kernel::KernelBuilder> & b,
                               StreamSet * symbolMarks,
                               StreamSet * symbolLengths,
                        StreamSet * const byteData, StreamSet * const hashValues, StreamSet * compressionMask, unsigned strideBlocks = 8)
    : MultiBlockKernel(b, "LengthGroupCompressionMask",
                              {Binding{"symbolMarks", symbolMarks},
                                  Binding{"symbolLengths", symbolLengths},
                                  Binding{"byteData", byteData, FixedRate(), {Deferred()}},
                                  Binding{"hashValues", hashValues}},
                              {Binding{"compressionMask", compressionMask, BoundedRate(0,1)}}, {}, {},
                              // Hash table 8 length-based tables with 256 16-byte entries each.
                              {InternalScalar{b->getBitBlockType(), "pendingMaskInverted"},
                                  InternalScalar{ArrayType::get(b->getInt8Ty(), 8 * 16 * 256), "hashTable"}}) {
                                      setStride(std::min(b->getBitBlockWidth() * strideBlocks, SIZE_T_BITS * SIZE_T_BITS));
                                  }
    bool isCachable() const override { return true; }
    bool hasSignature() const override { return false; }
private:
    void generateMultiBlockLogic(const std::unique_ptr<kernel::KernelBuilder> & iBuilder, llvm::Value * const numOfStrides) override;
};

void LengthGroupCompressionMask::generateMultiBlockLogic(const std::unique_ptr<KernelBuilder> & b, Value * const numOfStrides) {
    ScanWordParameters sw(b, mStride);
    Constant * sz_STRIDE = b->getSize(mStride);
    Constant * sz_BLOCKS_PER_STRIDE = b->getSize(mStride/b->getBitBlockWidth());
    Constant * sz_ZERO = b->getSize(0);
    Constant * sz_ONE = b->getSize(1);
    Constant * sz_BITS = b->getSize(SIZE_T_BITS);
    Constant * sz_MAXBIT = b->getSize(SIZE_T_BITS - 1);
    Type * sizeTy = b->getSizeTy();
    Type * int64PtrTy = b->getInt64Ty()->getPointerTo();

    BasicBlock * const entryBlock = b->GetInsertBlock();
    BasicBlock * const stridePrologue = b->CreateBasicBlock("stridePrologue");
    BasicBlock * const stridePrecomputation = b->CreateBasicBlock("stridePrecomputation");
    BasicBlock * const strideMasksReady = b->CreateBasicBlock("strideMasksReady");
    BasicBlock * const keyProcessingLoop = b->CreateBasicBlock("keyProcessingLoop");
    BasicBlock * const storeKey = b->CreateBasicBlock("storeKey");
    BasicBlock * const checkKey = b->CreateBasicBlock("checkKey");
    BasicBlock * const markCompression = b->CreateBasicBlock("markCompression");
    BasicBlock * const nextKey = b->CreateBasicBlock("nextKey");
    BasicBlock * const keysDone = b->CreateBasicBlock("keysDone");
    BasicBlock * const stridesDone = b->CreateBasicBlock("stridesDone");
    
    Value * const initialPos = b->getProcessedItemCount("symbolMarks");
    Value * const avail = b->getAvailableItemCount("symbolMarks");
    b->CreateBr(stridePrologue);
    
    b->SetInsertPoint(stridePrologue);
    // Set up the loop variables as PHI nodes at the beginning of each stride.
    PHINode * const strideNo = b->CreatePHI(sizeTy, 2);
    strideNo->addIncoming(sz_ZERO, entryBlock);
    Value * stridePos = b->CreateAdd(initialPos, b->CreateMul(strideNo, sz_STRIDE));
    Value * strideBlockOffset = b->CreateMul(strideNo, sz_BLOCKS_PER_STRIDE);
    Value * nextStrideNo = b->CreateAdd(strideNo, sz_ONE);
    Value * pendingMask = b->CreateNot(b->getScalarField("pendingMaskInverted"));
    
    b->CreateBr(stridePrecomputation);
    // Precompute an index mask for one stride of the symbol marks stream.
    b->SetInsertPoint(stridePrecomputation);
    PHINode * const keyMaskAccum = b->CreatePHI(sizeTy, 2);
    keyMaskAccum->addIncoming(sz_ZERO, stridePrologue);
    PHINode * const blockNo = b->CreatePHI(sizeTy, 2);
    blockNo->addIncoming(sz_ZERO, stridePrologue);
    PHINode * const pendingMaskPhi = b->CreatePHI(b->getBitBlockType(), 2);
    pendingMaskPhi->addIncoming(pendingMask, stridePrologue);
    Value * strideBlockIndex = b->CreateAdd(strideBlockOffset, blockNo);
    Value * keyBitBlock = b->loadInputStreamBlock("symbolMarks", sz_ZERO, strideBlockIndex);
    Value * const anyKey = b->simd_any(sw.width, keyBitBlock);
    Value * keyWordMask = b->CreateZExtOrTrunc(b->hsimd_signmask(sw.width, anyKey), sizeTy);
    Value * keyMask = b->CreateOr(keyMaskAccum, b->CreateShl(keyWordMask, b->CreateMul(blockNo, sw.WORDS_PER_BLOCK)), "keyMask");
    // Initialize the compression mask.
    b->storeOutputStreamBlock("compressionMask", sz_ZERO, blockNo, pendingMaskPhi);
    Value * const nextBlockNo = b->CreateAdd(blockNo, sz_ONE);
    keyMaskAccum->addIncoming(keyMask, stridePrecomputation);
    blockNo->addIncoming(nextBlockNo, stridePrecomputation);
    // Default initial compression mask is all ones (no zeroes => no compression).
    pendingMaskPhi->addIncoming(b->allOnes(), stridePrecomputation);
    b->CreateCondBr(b->CreateICmpNE(nextBlockNo, sz_BLOCKS_PER_STRIDE), stridePrecomputation, strideMasksReady);
    
    b->SetInsertPoint(strideMasksReady);
    // Iterate through key symbols and update the hash table as appropriate.
    // As symbols are encountered, the hash value is retrieved from the
    // hashValues stream.   There are then three possibilities:
    //   1.  The hashTable has no entry for this hash value.
    //       In this case, the current symbol is copied into the table.
    //   2.  The hashTable has an entry for this hash value, and
    //       that entry is equal to the current symbol.    Mark the
    //       symbol for compression.
    //   3.  The hashTable has an entry for this hash value, but
    //       that entry is not equal to the current symbol.    Skip the
    //       symbol.
    //
    Value * keyWordBasePtr = b->getInputStreamBlockPtr("symbolMarks", sz_ZERO, strideBlockOffset);
    keyWordBasePtr = b->CreateBitCast(keyWordBasePtr, sw.pointerTy);
    b->CreateUnlikelyCondBr(b->CreateICmpEQ(keyMask, sz_ZERO), keysDone, keyProcessingLoop);
    
    b->SetInsertPoint(keyProcessingLoop);
    PHINode * const keyMaskPhi = b->CreatePHI(sizeTy, 2);
    keyMaskPhi->addIncoming(keyMask, strideMasksReady);
    PHINode * const keyWordPhi = b->CreatePHI(sizeTy, 2);
    keyWordPhi->addIncoming(sz_ZERO, strideMasksReady);
    Value * keyWordIdx = b->CreateCountForwardZeroes(keyMaskPhi, "keyWordIdx");
    Value * nextKeyWord = b->CreateZExtOrTrunc(b->CreateLoad(b->CreateGEP(keyWordBasePtr, keyWordIdx)), sizeTy);
    Value * theKeyWord = b->CreateSelect(b->CreateICmpEQ(keyWordPhi, sz_ZERO), nextKeyWord, keyWordPhi);
    Value * keyWordPos = b->CreateAdd(stridePos, b->CreateMul(keyWordIdx, sw.WIDTH));
    Value * keyMarkPosInWord = b->CreateCountForwardZeroes(theKeyWord);
    Value * keyMarkPos = b->CreateAdd(keyWordPos, keyMarkPosInWord, "keyEndPos");
    //b->CallPrintInt("keyMarkPos", keyMarkPos);
    /* Determine the key length. */
    Value * const lgthPtr = b->getRawInputPointer("symbolLengths", keyMarkPos);
    Value * keyLength = b->CreateAdd(b->CreateZExt(b->CreateLoad(lgthPtr), sizeTy), b->getSize(2));
    Value * keyStartPos = b->CreateSub(keyMarkPos, b->CreateSub(keyLength, b->getSize(1)));
    //b->CallPrintInt("keyLength", keyLength);
    // keyOffset for accessing the final 8 bytes of an entry.
    Value * keyOffset = b->CreateSub(keyLength, b->getSize(8));
    //b->CallPrintInt("keyOffset", keyOffset);
    // Get the hash of this key.
    Value * const keyPtr = b->getRawInputPointer("hashValues", keyMarkPos);
    Value * keyHash = b->CreateZExt(b->CreateLoad(keyPtr), sizeTy);
    //b->CallPrintInt("keyHash", keyHash);
    // Starting with length 9, the length-based subtables are 16 * 256 = 4K each.
    Value * hashTableBasePtr = b->CreateBitCast(b->getScalarFieldPtr("hashTable"), b->getInt8PtrTy());
    //b->CallPrintInt("hashTableBasePtr", hashTableBasePtr);
    Value * hashTablePtr = b->CreateGEP(hashTableBasePtr, b->CreateMul(b->CreateSub(keyLength, b->getSize(9)), b->getSize(16 * 256)));
    //b->CallPrintInt("hashTablePtr", hashTablePtr);
    Value * tblEntryPtr = b->CreateGEP(hashTablePtr, b->CreateMul(keyHash, b->getSize(16)));
    // Use two 8-byte loads to get hash and symbol values.
    //b->CallPrintInt("tblEntryPtr", tblEntryPtr);
    Value * tblPtr1 = b->CreateBitCast(tblEntryPtr, int64PtrTy);
    //b->CallPrintInt("tblPtr1", tblPtr1);
    Value * tblPtr2 = b->CreateBitCast(b->CreateGEP(tblEntryPtr, keyOffset), int64PtrTy);
    //b->CallPrintInt("tblPtr2", tblPtr2);
    Value * symPtr1 = b->CreateBitCast(b->getRawInputPointer("byteData", b->getInt32(0), keyStartPos), int64PtrTy);
    //b->CallPrintInt("symPtr1", symPtr1);
    Value * symPtr2 = b->CreateBitCast(b->getRawInputPointer("byteData", b->getInt32(0), b->CreateAdd(keyStartPos, keyOffset)), int64PtrTy);
    //b->CallPrintInt("symPtr2", symPtr2);
    // Check to see if the hash table entry is nonzero (already assigned).
    Value * sym1 = b->CreateLoad(symPtr1);
    //b->CallPrintInt("sym1", sym1);
    Value * sym2 = b->CreateLoad(symPtr2);
    //b->CallPrintInt("sym2", sym2);
    Value * entry1 = b->CreateLoad(tblPtr1);
    //b->CallPrintInt("entry1", entry1);
    Value * entry2 = b->CreateLoad(tblPtr2);
    //b->CallPrintInt("entry2", entry2);
    Value * isEmptyEntry = b->CreateICmpEQ(b->CreateOr(entry1, entry2), b->getInt64(0));
    
    b->CreateCondBr(isEmptyEntry, storeKey, checkKey);
    b->SetInsertPoint(storeKey);
    // We have a new symbols that allows future occurrences of the symbol to
    // be compressed using the hash code.
    b->CreateStore(sym1, tblPtr1);
    b->CreateStore(sym2, tblPtr2);
    b->CreateBr(nextKey);
    
    b->SetInsertPoint(checkKey);
    // If the symbol is equal to the stored entry, it will be replace
    // by the ZTF compression code.  Prepare the compression mask by
    // zeroing out all symbol positions except the last two.
    Value * symIsEqEntry = b->CreateAnd(b->CreateICmpEQ(entry1, sym1), b->CreateICmpEQ(entry2, sym2));
    //b->CallPrintInt("symIsEqEntry", symIsEqEntry);
    b->CreateCondBr(symIsEqEntry, markCompression, nextKey);
    
    b->SetInsertPoint(markCompression);
    // Compute a mask of bits to zero out.
    Value * maskLength = b->CreateZExt(b->CreateSub(keyLength, b->getSize(2)), b->getInt64Ty());
    //b->CallPrintInt("maskLength", maskLength);
    Value * mask = b->CreateSub(b->CreateShl(b->getInt64(1), maskLength), b->getInt64(1));
    Value * bitOffset = b->CreateURem(keyStartPos, b->getSize(32));
    //b->CallPrintInt("bitOffset", bitOffset);
    mask = b->CreateShl(mask, bitOffset);
    //b->CallPrintInt("mask", mask);
    Value * keyBase = b->CreateSub(keyStartPos, bitOffset);
    Value * const keyBasePtr = b->CreateBitCast(b->getRawOutputPointer("compressionMask", keyBase), int64PtrTy);
    Value * initialMask = b->CreateLoad(keyBasePtr);
    //b->CallPrintInt("initialMask", initialMask);
    Value * updated = b->CreateAnd(initialMask, b->CreateNot(mask));
    //b->CallPrintInt("updated", updated);
    b->CreateStore(b->CreateAnd(updated, b->CreateNot(mask)), keyBasePtr);
    b->CreateBr(nextKey);
    
    b->SetInsertPoint(nextKey);
    Value * dropKey = b->CreateResetLowestBit(theKeyWord);
    Value * thisWordDone = b->CreateICmpEQ(dropKey, sz_ZERO);
    // There may be more keys in the key mask.
    Value * nextKeyMask = b->CreateSelect(thisWordDone, b->CreateResetLowestBit(keyMaskPhi), keyMaskPhi);
    BasicBlock * currentBB = b->GetInsertBlock();
    keyMaskPhi->addIncoming(nextKeyMask, currentBB);
    keyWordPhi->addIncoming(dropKey, currentBB);
    b->CreateCondBr(b->CreateICmpNE(nextKeyMask, sz_ZERO), keyProcessingLoop, keysDone);
    
    b->SetInsertPoint(keysDone);
    Value * maskPtr = b->getOutputStreamBlockPtr("compressionMask", sz_ZERO, strideNo);
    Value * lastMask = b->CreateBlockAlignedLoad(maskPtr);
    b->setScalarField("pendingMaskInverted", b->CreateNot(lastMask));
    strideNo->addIncoming(nextStrideNo, keysDone);
    b->CreateCondBr(b->CreateICmpNE(nextStrideNo, numOfStrides), stridePrologue, stridesDone);
    
    b->SetInsertPoint(stridesDone);
    // In the next segment, we may need to access byte data in the last
    // 16 bytes of this segment.
    Value * processed = b->CreateSelect(mIsFinal, avail, b->CreateSub(avail, b->getSize(16)));
    //b->CallPrintInt("avail", avail);
    b->setProcessedItemCount("byteData", processed);
    // Although we have written the last block mask, we do not include it as
    // produced, because we may need to update it in the event that there is
    // a compressible symbol starting in this segment and finishing in the next.
    Value * produced = b->CreateSelect(mIsFinal, avail, b->CreateSub(avail, b->getSize(b->getBitBlockWidth())));
    b->setProducedItemCount("compressionMask", produced);
    //b->CallPrintInt("produced", produced);
}



Redo wordMarks....

  

word_characters

ztf_symbols

word_character &~ ztf_symbol

word_start_
ztf_symbols


ZTF_Symbols
    PabloAST * WordCharByte1 = pb.createAnd(ASCII, WordChar);
    WordCharByte1 = pb.createOr(WordCharByte1, pb.createAnd(prefix2, pb.createLookahead(WordChar, 1)));
    WordCharByte1 = pb.createOr(WordCharByte1, pb.createAnd(prefix3 pb.createLookahead(WordChar, 2)));
    WordCharByte1 = pb.createOr(WordCharByte1, pb.createAnd(prefix4, pb.createLookahead(WordChar, 3)));
    //
    // But filter out ZTF symbols consisting of a prefix2 followed by ASCII.
    NonWordChar = pb.createAnd(u8index, pb.createNot(WordChar));
    //


    wordEnds = pb.createOr(wordEnds, pb.createAnd(prefix2, pb.createNot(pb.createLookahead(basis[7], 1))));
    wordEnds = pb.createOr(wordEnds, pb.createAnd(prefix3, pb.createLookahead(marks[1], 2)));
    wordEnds = pb.createOr(wordEnds, pb.createAnd(prefix4, pb.createLookahead(marks[1], 3)), "markedWordEnds");



class ZTF_Symbols : public PabloKernel {
public:
    ZTF_Symbols(const std::unique_ptr<KernelBuilder> & kb, StreamSet * EndMarks, StreamSet * SymbolRuns)
    : PabloKernel(kb, "ZTF_Symbols", {Binding{"EndMarks", EndMarks}}, {Binding{"SymbolRuns", SymbolRuns}}) { }
    bool isCachable() const override { return true; }
    bool hasSignature() const override { return false; }
protected:
    void generatePabloMethod() override;
};

void ZTF_Symbols::generatePabloMethod() {
    pablo::PabloBuilder pb(getEntryScope());
    std::vector<PabloAST *> basis = getInputStreamSet("source");
    cc::Parabix_CC_Compiler_Builder ccc(getEntryScope(), basis);
    pablo::PabloAST * wordChar = getInputStreamSet("wordChar")[0];
    // Find start bytes of word characters.
    PabloAST * ASCII = ccc.compileCC(re::makeCC(0x0, 0x7F));
    PabloAST * prefix2 = ccc.compileCC(re::makeCC(0xC2, 0xDF));
    PabloAST * prefix3 = ccc.compileCC(re::makeCC(0xE0, 0xEF));
    PabloAST * prefix4 = ccc.compileCC(re::makeCC(0xF0, 0xF4));
    PabloAST * wc1 = pb.createAnd(ASCII, wordChar);
    wc1 = pb.createOr(WordCharByte1, pb.createAnd(prefix2, pb.createLookahead(wordChar, 1)));
    wc1 = pb.createOr(WordCharByte1, pb.createAnd(prefix3 pb.createLookahead(wordChar, 2)));
    wc1 = pb.createOr(WordCharByte1, pb.createAnd(prefix4, pb.createLookahead(wordChar, 3)));
    //
    // ZTF Code symbols
    ZTF_sym = pb.createAnd(pb.createAdvance(prefix2, 1), ASCII);
    ZTF_prefix = pb.createAnd(pb.createNot(pb.createLookahead(basis[7], 1)));
    // Filter out ZTF code symbols from word characters.
    wc1 = pb.createAnd(wc1, pb.createNot(ZTF_sym);
    //
    PabloAST * wordStart = pb.createAnd(pb.createNot(pb.createAdvance(wordChar, 1)), wc1);
    // Nulls, Linefeeds and ZTF_symbols are also treated as symbol starts.
    PabloAST * LF = ccc.compileCC(re::makeByte(0x0A));
    PabloAST * Null = ccc.compileCC(re::makeByte(0x0));
    PabloAST * symStart = pb.createOr3(wc1, ZTF_prefix, pb.createOr(LF, Null));
    // The next character after a ZTF symbol or a line feed also starts a new symbol.
    symStart = pb.createOr(symStart, pb.createAdvance(ZTF_sym, LF);
    //
    // runs are the bytes after a start symbol until the next symStart byte.
    pablo::PabloAST * runs = pb.createInFile(pb.createNot(symStart));
    pb.createAssign(pb.createExtract(getOutputStreamVar("SymbolRuns"), pb.getInteger(0)), runs);
}
